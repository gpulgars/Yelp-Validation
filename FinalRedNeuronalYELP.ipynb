{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Neuronal para Análisis de sentimientos\n",
    "En el jupyter notebook se puede ver la construcción de un modelo SVM que predice el sentimiento de un comentario de redes sociales para dos productos ecuatorianos. Incluye la limpieza de datos, su preprocesamiento, preparación, construcción del modelo y evaluación del modelo."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 1\n",
    "# Importanción de librerías a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd     #permite manipular datos\n",
    "import numpy as np      #permite manipular números y matrices\n",
    "import seaborn as sns   #permite manipulacion mediante graficos\n",
    "sns.set_style(\"dark\")   \n",
    "import re               #proporciona coincidir con expresiones regulares\n",
    "import string           #permite trabajos con formatos str\n",
    "from string import punctuation\n",
    "import nltk             #permite la utilzación de natural lenguaje toolkit\n",
    "from nltk.corpus import stopwords  #bolsa de palabras stopwords\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier   #clasificador\n",
    "from sklearn.neighbors import KNeighborsClassifier    #clasificador\n",
    " \n",
    "import matplotlib.pyplot as plt                               #librería de gráficos\n",
    "from sklearn.model_selection import train_test_split         #permite entrenamiento de la data\n",
    "from sklearn.feature_extraction.text import CountVectorizer  #convertir token a vector\n",
    "from sklearn.feature_extraction.text import TfidfTransformer #utilizado para normalizar matrices \n",
    "\n",
    "import tensorflow as tf                                        #manejo con redes neuronales \n",
    "from tensorflow.keras.models import Sequential                 #manejo con redes neuronales \n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout #manejo con redes neuronales \n",
    "from tensorflow.keras.callbacks import EarlyStopping           #manejo con redes neuronales \n",
    "import tensorflow.keras.metrics                                #manejo con redes neuronales \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV               #optimizacion de hiperparámetros\n",
    "#from keras.models import Sequential, Model                     #manejo con redes neuronales \n",
    "from keras.layers import Activation, Dense, Dropout            #manejo con redes neuronales \n",
    "from keras.wrappers.scikit_learn import KerasClassifier        #manejo con redes neuronales  \n",
    "\n",
    "import pickle                                       #permite trabajo de datos como bytes\n",
    "from sklearn.preprocessing import LabelBinarizer    #permite trabajar desde un cjto Y a matriz\n",
    "import sklearn.datasets as skds                     #permite cargar archivos de texto\n",
    "from pathlib import Path                            #permite trabajar con rutas concretas\n",
    "import itertools                                    #permite crear iteradores para  bucles eficientes\n",
    "from sklearn.metrics import confusion_matrix        #permite trabajar con matriz de confusión\n",
    "# For reproducibility\n",
    "np.random.seed(1237)                                #fija numeros aleatorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#biblioteca'\n"
     ]
    }
   ],
   "source": [
    "pip install keras #biblioteca que permite la utilizacion de redes neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>Polarity_Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Guau ... Me encantó este lugar.</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La corteza no es buena.</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No es sabroso y la textura era simplemente des...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pasé por allí durante el feriado bancario de f...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La selección del menú era excelente, al igual ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content Polarity_Rating\n",
       "0                   Guau ... Me encantó este lugar.         Positive\n",
       "1                           La corteza no es buena.         Negative\n",
       "2  No es sabroso y la textura era simplemente des...        Negative\n",
       "3  Pasé por allí durante el feriado bancario de f...        Positive\n",
       "4  La selección del menú era excelente, al igual ...        Positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = pd.read_excel('Yelp.xlsx')  #Cargar los datos\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>Polarity_Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Guau ... Me encantó este lugar.</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La corteza no es buena.</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No es sabroso y la textura era simplemente des...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pasé por allí durante el feriado bancario de f...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La selección del menú era excelente, al igual ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content Polarity_Rating\n",
       "0                   Guau ... Me encantó este lugar.         Positive\n",
       "1                           La corteza no es buena.         Negative\n",
       "2  No es sabroso y la textura era simplemente des...        Negative\n",
       "3  Pasé por allí durante el feriado bancario de f...        Positive\n",
       "4  La selección del menú era excelente, al igual ...        Positive"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame()\n",
    "df2 = data\n",
    "#df2 = data.drop(['tweetid', 'user','value','country'], axis=1)\n",
    "#df2.dropna(inplace=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x246f1d0e850>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.countplot(x='Polarity_Rating',data=df2, palette='summer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative    500\n",
      "Positive    500\n",
      "Name: Polarity_Rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df2['Polarity_Rating'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2 Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['content'] = df2['content'].apply(lambda x: re.split('https:\\/\\/.*', str(x))[0]) #elimina url\n",
    "df2['content'] = df2['content'].apply(lambda x: re.split('\\d+', str(x))[0]) #elimina palabras con numeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>Polarity_Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Guau ... Me encantó este lugar.</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La corteza no es buena.</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No es sabroso y la textura era simplemente des...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pasé por alí durante el feriado bancario de fi...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La seleción del menú era excelente, al igual q...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Creo que la comida debería tener sabor y textu...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>El apetito desapareció instantáneamente.</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>En general, no me impresionó y no volvería.</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Toda la experiencia fue decepcionante, y creo ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Luego, como si no hubiera desperdiciado lo suf...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               content Polarity_Rating\n",
       "0                     Guau ... Me encantó este lugar.         Positive\n",
       "1                             La corteza no es buena.         Negative\n",
       "2    No es sabroso y la textura era simplemente des...        Negative\n",
       "3    Pasé por alí durante el feriado bancario de fi...        Positive\n",
       "4    La seleción del menú era excelente, al igual q...        Positive\n",
       "..                                                 ...             ...\n",
       "995  Creo que la comida debería tener sabor y textu...        Negative\n",
       "996          El apetito desapareció instantáneamente.         Negative\n",
       "997       En general, no me impresionó y no volvería.         Negative\n",
       "998  Toda la experiencia fue decepcionante, y creo ...        Negative\n",
       "999  Luego, como si no hubiera desperdiciado lo suf...        Negative\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#elimina palabras con letras repetidas\n",
    "def conti_rep_char(str1):\n",
    "    tchr = str1.group(0)\n",
    "    if len(tchr) > 1:\n",
    "      return tchr[0:1]\n",
    "      \n",
    "def check_unique_char(rep, sent_text):\n",
    "    \n",
    "    convert = re.sub(r'(\\w)\\1+', rep,sent_text)\n",
    "      \n",
    "    #regresa la palabra convertida\n",
    "    return convert\n",
    "  \n",
    "df2['content'] = df2['content'].apply(lambda x : check_unique_char(conti_rep_char,x))\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji \n",
    "\n",
    "def get_mentions_processing(text):\n",
    "    return \" \".join(filter(lambda x:x[0]!='@', text.split())) #no mentions\n",
    "\n",
    "def get_hashtags_processing(text):\n",
    "    return \" \".join(filter(lambda x:x[0]!='#', text.split())) #no hashtags\n",
    "\n",
    "def get_emojis_processing(text):\n",
    "    return str(emoji.demojize(text,language='es')).replace(\":\",\" \") #cambia emojis a texto\n",
    "\n",
    "def get_less3words_processing(text):\n",
    "    return ' '.join([word for word in text.split() if len(word)>2]) #elimina palabras con menos de 3 caracteres\n",
    "\n",
    "def get_text_processing(text):\n",
    "    stpword = stopwords.words('spanish')\n",
    "    non_words = list(punctuation) #considera ¿ y ¡\n",
    "    non_words.extend(['¿', '¡'])\n",
    "    no_punctuation = [char for char in text if char not in non_words] #elimina puntuacion\n",
    "    no_punctuation = ''.join(no_punctuation).lower() #convierte en minuscula\n",
    "    return ' '.join([word for word in no_punctuation.split() if word.lower() not in stpword]) #elimina stopwords\n",
    "\n",
    "def normalize(s): #elimina las vocales con tilde\n",
    "    replacements = (\n",
    "        (\"á\", \"a\"),\n",
    "        (\"é\", \"e\"),\n",
    "        (\"í\", \"i\"),\n",
    "        (\"ó\", \"o\"),\n",
    "        (\"ú\", \"u\"),\n",
    "    )\n",
    "    for a, b in replacements:\n",
    "        s = s.replace(a, b).replace(a.upper(), b.upper())\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>Polarity_Rating</th>\n",
       "      <th>Content_Review</th>\n",
       "      <th>Content_Review1</th>\n",
       "      <th>Content_Review2</th>\n",
       "      <th>Content_Review3</th>\n",
       "      <th>Content_Review4</th>\n",
       "      <th>Content_Review5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>El mejor lugar para desayunar en Las Vegas (so...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>El mejor lugar para desayunar en Las Vegas (so...</td>\n",
       "      <td>El mejor lugar para desayunar en Las Vegas (so...</td>\n",
       "      <td>El mejor lugar para desayunar en Las Vegas (so...</td>\n",
       "      <td>mejor lugar desayunar vegas solo echa vistazo ...</td>\n",
       "      <td>mejor lugar desayunar vegas solo echa vistazo ...</td>\n",
       "      <td>mejor lugar desayunar vegas solo echa vistazo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mi bebida nunca estuvo vacía e hizo algunas su...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Mi bebida nunca estuvo vacía e hizo algunas su...</td>\n",
       "      <td>Mi bebida nunca estuvo vacía e hizo algunas su...</td>\n",
       "      <td>Mi bebida nunca estuvo vacía e hizo algunas su...</td>\n",
       "      <td>bebida nunca vacía hizo sugerencias menú realm...</td>\n",
       "      <td>bebida nunca vacía hizo sugerencias menú realm...</td>\n",
       "      <td>bebida nunca vacia hizo sugerencias menu realm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>En general, no me impresionó mucho Noca.</td>\n",
       "      <td>Negative</td>\n",
       "      <td>En general, no me impresionó mucho Noca.</td>\n",
       "      <td>En general, no me impresionó mucho Noca.</td>\n",
       "      <td>En general, no me impresionó mucho Noca.</td>\n",
       "      <td>general impresionó noca</td>\n",
       "      <td>general impresionó noca</td>\n",
       "      <td>general impresiono noca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>La administración es de mala educación.</td>\n",
       "      <td>Negative</td>\n",
       "      <td>La administración es de mala educación.</td>\n",
       "      <td>La administración es de mala educación.</td>\n",
       "      <td>La administración es de mala educación.</td>\n",
       "      <td>administración mala educación</td>\n",
       "      <td>administración mala educación</td>\n",
       "      <td>administracion mala educacion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La comida está a la par con Deny's, lo que qui...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>La comida está a la par con Deny's, lo que qui...</td>\n",
       "      <td>La comida está a la par con Deny's, lo que qui...</td>\n",
       "      <td>La comida está a la par con Deny's, lo que qui...</td>\n",
       "      <td>comida par denys quiere decir bueno</td>\n",
       "      <td>comida par denys quiere decir bueno</td>\n",
       "      <td>comida par denys quiere decir bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>La mejor de las suertes para la nueva administ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>La mejor de las suertes para la nueva administ...</td>\n",
       "      <td>La mejor de las suertes para la nueva administ...</td>\n",
       "      <td>La mejor de las suertes para la nueva administ...</td>\n",
       "      <td>mejor suertes nueva administración mala educac...</td>\n",
       "      <td>mejor suertes nueva administración mala educac...</td>\n",
       "      <td>mejor suertes nueva administracion mala educac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>El restaurante está muy limpio y tiene un ambi...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>El restaurante está muy limpio y tiene un ambi...</td>\n",
       "      <td>El restaurante está muy limpio y tiene un ambi...</td>\n",
       "      <td>El restaurante está muy limpio y tiene un ambi...</td>\n",
       "      <td>restaurante limpio ambiente familiar</td>\n",
       "      <td>restaurante limpio ambiente familiar</td>\n",
       "      <td>restaurante limpio ambiente familiar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Nos sentamos bastante rápido, pero terminamos ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Nos sentamos bastante rápido, pero terminamos ...</td>\n",
       "      <td>Nos sentamos bastante rápido, pero terminamos ...</td>\n",
       "      <td>Nos sentamos bastante rápido, pero terminamos ...</td>\n",
       "      <td>sentamos bastante rápido terminamos esperando</td>\n",
       "      <td>sentamos bastante rápido terminamos esperando</td>\n",
       "      <td>sentamos bastante rapido terminamos esperando</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>¡A este lugar le faltaba estilo!</td>\n",
       "      <td>Negative</td>\n",
       "      <td>¡A este lugar le faltaba estilo!</td>\n",
       "      <td>¡A este lugar le faltaba estilo!</td>\n",
       "      <td>¡A este lugar le faltaba estilo!</td>\n",
       "      <td>lugar faltaba estilo</td>\n",
       "      <td>lugar faltaba estilo</td>\n",
       "      <td>lugar faltaba estilo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Hasta ahora, solo he visitado dos veces y la c...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Hasta ahora, solo he visitado dos veces y la c...</td>\n",
       "      <td>Hasta ahora, solo he visitado dos veces y la c...</td>\n",
       "      <td>Hasta ahora, solo he visitado dos veces y la c...</td>\n",
       "      <td>ahora solo visitado dos veces comida absolutam...</td>\n",
       "      <td>ahora solo visitado dos veces comida absolutam...</td>\n",
       "      <td>ahora solo visitado dos veces comida absolutam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               content Polarity_Rating  \\\n",
       "0    El mejor lugar para desayunar en Las Vegas (so...        Positive   \n",
       "1    Mi bebida nunca estuvo vacía e hizo algunas su...        Positive   \n",
       "2            En general, no me impresionó mucho Noca.         Negative   \n",
       "3             La administración es de mala educación.         Negative   \n",
       "4    La comida está a la par con Deny's, lo que qui...        Negative   \n",
       "..                                                 ...             ...   \n",
       "995  La mejor de las suertes para la nueva administ...        Negative   \n",
       "996  El restaurante está muy limpio y tiene un ambi...        Positive   \n",
       "997  Nos sentamos bastante rápido, pero terminamos ...        Negative   \n",
       "998                  ¡A este lugar le faltaba estilo!         Negative   \n",
       "999  Hasta ahora, solo he visitado dos veces y la c...        Positive   \n",
       "\n",
       "                                        Content_Review  \\\n",
       "0    El mejor lugar para desayunar en Las Vegas (so...   \n",
       "1    Mi bebida nunca estuvo vacía e hizo algunas su...   \n",
       "2             En general, no me impresionó mucho Noca.   \n",
       "3              La administración es de mala educación.   \n",
       "4    La comida está a la par con Deny's, lo que qui...   \n",
       "..                                                 ...   \n",
       "995  La mejor de las suertes para la nueva administ...   \n",
       "996  El restaurante está muy limpio y tiene un ambi...   \n",
       "997  Nos sentamos bastante rápido, pero terminamos ...   \n",
       "998                   ¡A este lugar le faltaba estilo!   \n",
       "999  Hasta ahora, solo he visitado dos veces y la c...   \n",
       "\n",
       "                                       Content_Review1  \\\n",
       "0    El mejor lugar para desayunar en Las Vegas (so...   \n",
       "1    Mi bebida nunca estuvo vacía e hizo algunas su...   \n",
       "2             En general, no me impresionó mucho Noca.   \n",
       "3              La administración es de mala educación.   \n",
       "4    La comida está a la par con Deny's, lo que qui...   \n",
       "..                                                 ...   \n",
       "995  La mejor de las suertes para la nueva administ...   \n",
       "996  El restaurante está muy limpio y tiene un ambi...   \n",
       "997  Nos sentamos bastante rápido, pero terminamos ...   \n",
       "998                   ¡A este lugar le faltaba estilo!   \n",
       "999  Hasta ahora, solo he visitado dos veces y la c...   \n",
       "\n",
       "                                       Content_Review2  \\\n",
       "0    El mejor lugar para desayunar en Las Vegas (so...   \n",
       "1    Mi bebida nunca estuvo vacía e hizo algunas su...   \n",
       "2             En general, no me impresionó mucho Noca.   \n",
       "3              La administración es de mala educación.   \n",
       "4    La comida está a la par con Deny's, lo que qui...   \n",
       "..                                                 ...   \n",
       "995  La mejor de las suertes para la nueva administ...   \n",
       "996  El restaurante está muy limpio y tiene un ambi...   \n",
       "997  Nos sentamos bastante rápido, pero terminamos ...   \n",
       "998                   ¡A este lugar le faltaba estilo!   \n",
       "999  Hasta ahora, solo he visitado dos veces y la c...   \n",
       "\n",
       "                                       Content_Review3  \\\n",
       "0    mejor lugar desayunar vegas solo echa vistazo ...   \n",
       "1    bebida nunca vacía hizo sugerencias menú realm...   \n",
       "2                              general impresionó noca   \n",
       "3                        administración mala educación   \n",
       "4                  comida par denys quiere decir bueno   \n",
       "..                                                 ...   \n",
       "995  mejor suertes nueva administración mala educac...   \n",
       "996               restaurante limpio ambiente familiar   \n",
       "997      sentamos bastante rápido terminamos esperando   \n",
       "998                               lugar faltaba estilo   \n",
       "999  ahora solo visitado dos veces comida absolutam...   \n",
       "\n",
       "                                       Content_Review4  \\\n",
       "0    mejor lugar desayunar vegas solo echa vistazo ...   \n",
       "1    bebida nunca vacía hizo sugerencias menú realm...   \n",
       "2                              general impresionó noca   \n",
       "3                        administración mala educación   \n",
       "4                  comida par denys quiere decir bueno   \n",
       "..                                                 ...   \n",
       "995  mejor suertes nueva administración mala educac...   \n",
       "996               restaurante limpio ambiente familiar   \n",
       "997      sentamos bastante rápido terminamos esperando   \n",
       "998                               lugar faltaba estilo   \n",
       "999  ahora solo visitado dos veces comida absolutam...   \n",
       "\n",
       "                                       Content_Review5  \n",
       "0    mejor lugar desayunar vegas solo echa vistazo ...  \n",
       "1    bebida nunca vacia hizo sugerencias menu realm...  \n",
       "2                              general impresiono noca  \n",
       "3                        administracion mala educacion  \n",
       "4                  comida par denys quiere decir bueno  \n",
       "..                                                 ...  \n",
       "995  mejor suertes nueva administracion mala educac...  \n",
       "996               restaurante limpio ambiente familiar  \n",
       "997      sentamos bastante rapido terminamos esperando  \n",
       "998                               lugar faltaba estilo  \n",
       "999  ahora solo visitado dos veces comida absolutam...  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df2.sample(frac=1).reset_index(drop=True)\n",
    "df3 = pd.DataFrame()\n",
    "df3 = df2\n",
    "df3['content'] = df2['content']\n",
    "df3['Content_Review'] = df2['content'].apply(get_mentions_processing)\n",
    "df3['Content_Review1'] = df3['Content_Review'].apply(get_hashtags_processing)\n",
    "df3['Content_Review2'] = df3['Content_Review1'].apply(get_emojis_processing)\n",
    "df3['Content_Review3'] = df3['Content_Review2'].apply(get_text_processing)\n",
    "df3['Content_Review4'] = df3['Content_Review3'].apply(get_less3words_processing)\n",
    "df3['Content_Review5'] = df3['Content_Review4'].apply(normalize)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content_Review5</th>\n",
       "      <th>Polarity_Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mejor lugar desayunar vegas solo echa vistazo ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bebida nunca vacia hizo sugerencias menu realm...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>general impresiono noca</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>administracion mala educacion</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comida par denys quiere decir bueno</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Content_Review5 Polarity_Rating\n",
       "0  mejor lugar desayunar vegas solo echa vistazo ...        Positive\n",
       "1  bebida nunca vacia hizo sugerencias menu realm...        Positive\n",
       "2                            general impresiono noca        Negative\n",
       "3                      administracion mala educacion        Negative\n",
       "4                comida par denys quiere decir bueno        Negative"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = pd.DataFrame()\n",
    "df4 = df3\n",
    "df4 = df3[['Content_Review5', 'Polarity_Rating']]\n",
    "print(df4.shape)\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "(994, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gpulg\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6746: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content_Review5</th>\n",
       "      <th>Polarity_Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mejor lugar desayunar vegas solo echa vistazo ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bebida nunca vacia hizo sugerencias menu realm...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>general impresiono noca</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>administracion mala educacion</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comida par denys quiere decir bueno</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>mejor suertes nueva administracion mala educac...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>restaurante limpio ambiente familiar</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>sentamos bastante rapido terminamos esperando</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>lugar faltaba estilo</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>ahora solo visitado dos veces comida absolutam...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>994 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Content_Review5 Polarity_Rating\n",
       "0    mejor lugar desayunar vegas solo echa vistazo ...        Positive\n",
       "1    bebida nunca vacia hizo sugerencias menu realm...        Positive\n",
       "2                              general impresiono noca        Negative\n",
       "3                        administracion mala educacion        Negative\n",
       "4                  comida par denys quiere decir bueno        Negative\n",
       "..                                                 ...             ...\n",
       "995  mejor suertes nueva administracion mala educac...        Negative\n",
       "996               restaurante limpio ambiente familiar        Positive\n",
       "997      sentamos bastante rapido terminamos esperando        Negative\n",
       "998                               lugar faltaba estilo        Negative\n",
       "999  ahora solo visitado dos veces comida absolutam...        Positive\n",
       "\n",
       "[994 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Elimino registros con Answers NaN\n",
    "df4['Content_Review5'].replace('', np.nan, inplace=True) # Reemplazo los registros vacíos con NaN\n",
    "print(df4['Content_Review5'].isna().sum()) \n",
    "df4 = df4.dropna(axis=0, subset=['Content_Review5'])\n",
    "print(df4.shape)\n",
    "df4"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#3 \n",
    "#Manipulación previa al algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df4['Content_Review5'].values #se definen como valores\n",
    "y=df4['Polarity_Rating'].values #se definen como valores\n",
    "\n",
    "#Partición de la base entre testeo y entrenamiento\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, train_size=0.70, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(994,)\n",
      "(994,)\n",
      "(695,)\n",
      "(299,)\n",
      "(695,)\n",
      "(299,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Positive', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Negative', 'Negative', 'Negative',\n",
       "       'Negative', 'Positive', 'Negative', 'Positive', 'Positive',\n",
       "       'Negative', 'Negative', 'Positive', 'Negative', 'Positive',\n",
       "       'Negative', 'Negative', 'Negative', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Negative', 'Positive', 'Positive',\n",
       "       'Negative', 'Positive', 'Negative', 'Negative', 'Positive',\n",
       "       'Positive', 'Negative', 'Negative', 'Negative', 'Negative',\n",
       "       'Negative', 'Negative', 'Positive', 'Negative', 'Negative',\n",
       "       'Positive', 'Negative', 'Positive', 'Negative', 'Negative',\n",
       "       'Positive', 'Positive', 'Negative', 'Positive', 'Negative',\n",
       "       'Negative', 'Positive', 'Negative', 'Negative', 'Negative',\n",
       "       'Negative', 'Positive', 'Negative', 'Negative', 'Negative',\n",
       "       'Positive', 'Negative', 'Negative', 'Negative', 'Positive',\n",
       "       'Positive', 'Negative', 'Negative', 'Negative', 'Negative',\n",
       "       'Negative', 'Negative', 'Positive', 'Positive', 'Negative',\n",
       "       'Negative', 'Negative', 'Negative', 'Positive', 'Positive',\n",
       "       'Negative', 'Positive', 'Positive', 'Negative', 'Positive',\n",
       "       'Positive', 'Negative', 'Positive', 'Positive', 'Positive',\n",
       "       'Negative', 'Positive', 'Negative', 'Negative', 'Negative',\n",
       "       'Negative', 'Positive', 'Negative', 'Positive', 'Positive',\n",
       "       'Negative', 'Negative', 'Negative', 'Positive', 'Positive',\n",
       "       'Positive', 'Negative', 'Positive', 'Positive', 'Negative',\n",
       "       'Negative', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Negative', 'Negative', 'Negative', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Negative', 'Negative', 'Negative',\n",
       "       'Positive', 'Negative', 'Negative', 'Positive', 'Positive',\n",
       "       'Negative', 'Positive', 'Negative', 'Positive', 'Positive',\n",
       "       'Positive', 'Negative', 'Positive', 'Positive', 'Negative',\n",
       "       'Positive', 'Positive', 'Negative', 'Negative', 'Negative',\n",
       "       'Positive', 'Negative', 'Negative', 'Negative', 'Positive',\n",
       "       'Positive', 'Negative', 'Negative', 'Negative', 'Negative',\n",
       "       'Positive', 'Positive', 'Positive', 'Negative', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Negative',\n",
       "       'Positive', 'Negative', 'Positive', 'Positive', 'Positive',\n",
       "       'Negative', 'Positive', 'Positive', 'Positive', 'Negative',\n",
       "       'Negative', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Negative', 'Negative', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Negative', 'Positive', 'Positive', 'Positive',\n",
       "       'Negative', 'Negative', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Negative', 'Negative',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Negative', 'Positive', 'Positive', 'Negative', 'Positive',\n",
       "       'Negative', 'Positive', 'Negative', 'Positive', 'Positive',\n",
       "       'Negative', 'Positive', 'Negative', 'Positive', 'Negative',\n",
       "       'Negative', 'Negative', 'Negative', 'Positive', 'Negative',\n",
       "       'Positive', 'Positive', 'Negative', 'Positive', 'Negative',\n",
       "       'Negative', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Negative', 'Negative', 'Negative', 'Negative',\n",
       "       'Negative', 'Negative', 'Negative', 'Negative', 'Positive',\n",
       "       'Negative', 'Negative', 'Negative', 'Negative', 'Positive',\n",
       "       'Positive', 'Positive', 'Negative', 'Positive', 'Positive',\n",
       "       'Negative', 'Positive', 'Negative', 'Negative', 'Positive',\n",
       "       'Negative', 'Negative', 'Positive', 'Positive', 'Positive',\n",
       "       'Negative', 'Negative', 'Positive', 'Negative', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Negative',\n",
       "       'Positive', 'Negative', 'Positive', 'Negative', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect1 = CountVectorizer(min_df=2,ngram_range=(1,1)) #transformo los X (values) en vectores \n",
    "X_train = vect1.fit_transform(X_train) \n",
    "X_test = vect1.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(695, 550)\n",
      "(299, 550)\n",
      "(695,)\n",
      "(299,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelBinarizer()  #Transformo los Y (values) en vectores\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size=int(len(df4) * .7)              #permite la visualización más adelante en la matriz de confusión\n",
    "test_tags=df4['Polarity_Rating'][train_size:] #permite la visualización más adelante en la matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(695, 550)\n",
      "(299, 550)\n",
      "(695, 1)\n",
      "(299, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer(smooth_idf=True,use_idf=True) #Entrega ponderación de importancia a palabras más \"importantes\" (frecuentes)\n",
    "X_train = tfidf.fit_transform(X_train)\n",
    "X_test = tfidf.transform(X_test)\n",
    "X_train = X_train.toarray()\n",
    "X_test = X_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>comida</th>\n",
       "      <td>3.091002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lugar</th>\n",
       "      <td>3.150901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>servicio</th>\n",
       "      <td>3.418215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aqui</th>\n",
       "      <td>3.807680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tan</th>\n",
       "      <td>4.213145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mantuvo</th>\n",
       "      <td>6.446737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mantequila</th>\n",
       "      <td>6.446737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mama</th>\n",
       "      <td>6.446737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>masticable</th>\n",
       "      <td>6.446737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yendo</th>\n",
       "      <td>6.446737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>550 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            idf_weights\n",
       "comida         3.091002\n",
       "lugar          3.150901\n",
       "servicio       3.418215\n",
       "aqui           3.807680\n",
       "tan            4.213145\n",
       "...                 ...\n",
       "mantuvo        6.446737\n",
       "mantequila     6.446737\n",
       "mama           6.446737\n",
       "masticable     6.446737\n",
       "yendo          6.446737\n",
       "\n",
       "[550 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print idf values \n",
    "df_idf = pd.DataFrame(tfidf.idf_, index=vect1.get_feature_names(),columns=[\"idf_weights\"]) \n",
    " \n",
    "# sort ascending \n",
    "df_idf.sort_values(by=['idf_weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(695, 550)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(695, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#4 \n",
    "Aplicación del algoritmo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.1 red aplicada\n",
    "from keras.constraints import maxnorm\n",
    "from tensorflow import keras\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]\n",
    "\n",
    "model = Sequential()                                         #Se define estructura de la red capa por capa\n",
    "model.add(Dense(units=1500, kernel_initializer='uniform', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.9))\n",
    "model.add(Dense(units=1200,kernel_initializer='uniform', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.9))\n",
    "model.add(Dense(units=1,kernel_initializer='zero', activation='softmax'))\n",
    "\n",
    "#optimizer=tf.keras.optimizers.Adamax(0.001)\n",
    "#model.compile(optimizer= 'adam' , loss= keras.losses.binary_crossentropy, metrics=['accuracy'])\n",
    "model.compile(optimizer = 'adam',loss='categorical_crossentropy', metrics=METRICS)  #Se compila la red en conjunto a su optimizador\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 - 7s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 2/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 3/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 4/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 5/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 6/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 7/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 8/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 9/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 10/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 11/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 12/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 13/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 14/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 15/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 16/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 17/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 18/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 19/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 20/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 21/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 23/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 24/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 25/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 26/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 27/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 28/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 29/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 30/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 31/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 32/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 33/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 34/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 35/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 36/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 37/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 38/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 39/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 40/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 41/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 42/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 44/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 45/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 46/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 47/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 48/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 49/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 50/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 51/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 52/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 53/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 54/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 55/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 56/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 57/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 58/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 59/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 60/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 61/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 62/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 63/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 65/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 66/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 67/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 68/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 69/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 70/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 71/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 72/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 73/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 74/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 75/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 76/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 77/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 78/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 79/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 80/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 81/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 82/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 83/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 84/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 86/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 87/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 88/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 89/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 90/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 91/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 92/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 93/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 94/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 95/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 96/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 97/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 98/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 99/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n",
      "Epoch 100/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - tp: 236.0000 - fp: 250.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4856 - recall: 1.0000 - auc: 0.5000 - prc: 0.4856 - val_loss: 0.0000e+00 - val_tp: 98.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.4689 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4689\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=256, epochs=100, validation_split=0.3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0000e+00 - tp: 162.0000 - fp: 137.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.5418 - recall: 1.0000 - auc: 0.5000 - prc: 0.5418\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=64, verbose=1)  #Evaluar el modelo.\n",
    "\n",
    "#print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.724283 using {'optimizer': 'Adamax'}\n",
      "0.721192 (0.009090) with: {'optimizer': 'SGD'}\n",
      "0.724002 (0.001733) with: {'optimizer': 'RMSprop'}\n",
      "0.579820 (0.011465) with: {'optimizer': 'Adagrad'}\n",
      "0.570264 (0.021610) with: {'optimizer': 'Adadelta'}\n",
      "0.671726 (0.012341) with: {'optimizer': 'Adam'}\n",
      "0.724283 (0.004819) with: {'optimizer': 'Adamax'}\n",
      "0.669477 (0.007188) with: {'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "#OPTIMIZER ALGORITHM\n",
    "# Use scikit-learn to grid search the batch size and epochs\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer='adam'):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(12, input_dim=2398, activation='relu'))\n",
    "\tmodel.add(Dense(3, activation='hard_sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\treturn model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load dataset\n",
    "Xx = X_train\n",
    "Yy = y_train\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(Xx, Yy)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.703766 using {'activation': 'hard_sigmoid'}\n",
      "0.699831 (0.006310) with: {'activation': 'softmax'}\n",
      "0.682406 (0.006397) with: {'activation': 'softplus'}\n",
      "0.667229 (0.007297) with: {'activation': 'softsign'}\n",
      "0.675379 (0.003577) with: {'activation': 'relu'}\n",
      "0.661046 (0.008789) with: {'activation': 'tanh'}\n",
      "0.694210 (0.005167) with: {'activation': 'sigmoid'}\n",
      "0.703766 (0.006757) with: {'activation': 'hard_sigmoid'}\n",
      "0.663575 (0.005377) with: {'activation': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Use scikit-learn to grid search the activation function\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(activation='relu'):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(12, input_dim=2398, kernel_initializer='uniform', activation=activation))\n",
    "\tmodel.add(Dense(3, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load dataset\n",
    "Xx = X_train\n",
    "Yy = y_train\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "param_grid = dict(activation=activation)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(Xx, Yy)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#4\n",
    "#Aplicación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.constraints import maxnorm\n",
    "from tensorflow import keras\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=1500, kernel_initializer='uniform', activation='hard_sigmoid', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1200,kernel_initializer='uniform', activation='hard_sigmoid', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=2,kernel_initializer='zero', activation='softmax'))\n",
    "\n",
    "#optimizer=tf.keras.optimizers.Adamax(0.001)\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=METRICS)\n",
    "model.compile(optimizer = 'Adamax',loss='categorical_crossentropy', metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\gpulg\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:855 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\gpulg\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\gpulg\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\gpulg\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\gpulg\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\gpulg\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:838 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\gpulg\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 train_step\n        loss = self.compiled_loss(\n    C:\\Users\\gpulg\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\gpulg\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\losses.py:155 __call__\n        losses = call_fn(y_true, y_pred)\n    C:\\Users\\gpulg\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\losses.py:259 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\gpulg\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\gpulg\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\losses.py:1643 categorical_crossentropy\n        return backend.categorical_crossentropy(\n    C:\\Users\\gpulg\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\gpulg\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\backend.py:4862 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    C:\\Users\\gpulg\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 1) and (None, 2) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-4291b5e3718e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 763\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    764\u001b[0m             *args, **kwds))\n\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3049\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3050\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3051\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3444\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3279\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\gpulg\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:855 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\gpulg\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\gpulg\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\gpulg\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\gpulg\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\gpulg\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:838 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\gpulg\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 train_step\n        loss = self.compiled_loss(\n    C:\\Users\\gpulg\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\gpulg\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\losses.py:155 __call__\n        losses = call_fn(y_true, y_pred)\n    C:\\Users\\gpulg\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\losses.py:259 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\gpulg\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\gpulg\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\losses.py:1643 categorical_crossentropy\n        return backend.categorical_crossentropy(\n    C:\\Users\\gpulg\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\gpulg\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\backend.py:4862 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    C:\\Users\\gpulg\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 1) and (None, 2) are incompatible\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=256, epochs=100, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - tp: 162.0000 - fp: 137.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.5418 - recall: 1.0000 - auc: 0.5000 - prc: 0.5418\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=64, verbose=1)\n",
    "\n",
    "#print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(prediction, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_labels = np.argmax(y_test, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_labels = np.argmax(y_train, axis =1)\n",
    "y_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.0}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#from sklearn.utils import class_weight   #Estima los pesos de las clases\n",
    "#weight = class_weight.compute_class_weight('balanced', np.unique(y_train_labels), y_train_labels)\n",
    "#weight = {i : weight[i] for i in range(1)}\n",
    "#weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 2/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 3/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 4/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 5/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 6/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 7/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 8/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 9/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 10/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 11/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 12/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 13/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 14/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 15/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 16/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 17/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 18/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 19/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 20/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 21/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 23/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 24/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 25/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 26/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 27/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 28/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 29/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 30/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 31/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 32/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 33/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 34/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 35/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 36/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 37/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 38/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 39/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 40/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 41/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 42/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 44/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 45/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 46/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 47/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 48/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 49/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 50/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 51/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 52/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 53/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 54/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 55/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 56/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 57/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 58/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 59/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 60/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 61/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 62/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 63/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 65/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 66/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 67/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 68/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 69/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 70/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 71/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 72/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 73/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 74/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 75/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 76/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 77/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 78/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 79/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 80/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 81/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 82/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 83/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 84/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 86/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 87/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 88/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 89/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 90/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 91/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 92/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 93/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 94/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 95/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 96/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 97/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 98/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 99/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 100/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 101/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 102/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 103/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 104/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 105/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 107/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 108/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 109/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 110/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 111/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 112/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 113/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 114/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 115/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 116/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 117/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 118/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 119/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 120/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 121/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 122/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 123/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 124/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 125/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 126/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 128/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 129/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 130/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 131/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 132/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 133/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 134/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 135/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 136/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 137/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 138/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 139/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 140/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 141/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 142/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 143/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 144/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 145/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 146/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 147/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 149/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 150/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 151/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 152/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 153/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 154/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 155/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 156/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 157/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 158/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 159/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 160/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 161/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 162/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 163/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 164/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 165/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 166/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 167/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 168/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 170/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 171/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 172/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 173/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 174/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 175/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 176/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 177/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 178/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 179/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 180/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 181/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 182/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 183/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 184/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 185/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 186/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 187/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 188/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 189/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 191/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 192/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 193/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 194/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 195/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 196/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 197/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 198/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 199/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n",
      "Epoch 200/200\n",
      "3/3 - 0s - loss: 0.0000e+00 - tp: 261.0000 - fp: 295.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.4694 - recall: 1.0000 - auc: 0.5000 - prc: 0.4694 - val_loss: 0.0000e+00 - val_tp: 73.0000 - val_fp: 66.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.5252 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.5252\n"
     ]
    }
   ],
   "source": [
    "num_epochs =200\n",
    "batch_size = 256\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs,\n",
    "                    verbose=2,\n",
    "                    #class_weight=weight,   #con el class_weight le digo al modelo q tenga especial atencion con la clase sobre/infra representada \n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0000e+00 - tp: 162.0000 - fp: 137.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 0.5418 - recall: 1.0000 - auc: 0.5000 - prc: 0.5418\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=64, verbose=1)  #Evaluar el modelo.\n",
    "\n",
    "#print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_metrics(history):\n",
    "  metrics = ['loss', 'accuracy', 'precision', 'recall']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(2,2,n+1)\n",
    "    plt.plot(history.epoch, history.history[metric], label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_'+metric], linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    elif metric == 'auc':\n",
    "      plt.ylim([0.8,1])\n",
    "    else:\n",
    "      plt.ylim([0,1])\n",
    "\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weight = class_weight.compute_class_weight('balanced' ,np.unique(y_train_labels) ,y_train_labels)\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual label:Positive\n",
      "Predicted label: Negative\n",
      "Actual label:Negative\n",
      "Predicted label: Negative\n",
      "Actual label:Positive\n",
      "Predicted label: Negative\n",
      "Actual label:Negative\n",
      "Predicted label: Negative\n",
      "Actual label:Negative\n",
      "Predicted label: Negative\n",
      "Actual label:Negative\n",
      "Predicted label: Negative\n",
      "Actual label:Negative\n",
      "Predicted label: Negative\n",
      "Actual label:Positive\n",
      "Predicted label: Negative\n",
      "Actual label:Positive\n",
      "Predicted label: Negative\n",
      "Actual label:Negative\n",
      "Predicted label: Negative\n",
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x864 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "text_labels = encoder.classes_\n",
    "label_names=['Positive','Neutral','Negative']\n",
    "\n",
    "for i in range(10):\n",
    "    prediction = model.predict(np.array([X_test[i]]))\n",
    "    predicted_label = text_labels[np.argmax(prediction[0])]\n",
    "    #print(test_files_names.iloc[i])\n",
    "    print('Actual label:' + test_tags.iloc[i])\n",
    "    print(\"Predicted label: \" + predicted_label)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    # print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test);\n",
    "cnf_matrix = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(14, 12, forward=True)\n",
    "#fig.align_labels()\n",
    "\n",
    "# fig.subplots_adjust(left=0.0, right=1.0, bottom=0.0, top=1.0)\n",
    "plot_confusion_matrix(cnf_matrix, classes=np.asarray(label_names), normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "fig.savefig(\"txt_classification-smote\" + str(num_epochs) + \".png\", pad_inches=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Positive', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Negative', 'Negative', 'Negative',\n",
       "       'Negative', 'Positive', 'Negative', 'Positive', 'Positive',\n",
       "       'Negative', 'Negative', 'Positive', 'Negative', 'Positive',\n",
       "       'Negative', 'Negative', 'Negative', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Negative', 'Positive', 'Positive',\n",
       "       'Negative', 'Positive', 'Negative', 'Negative', 'Positive',\n",
       "       'Positive', 'Negative', 'Negative', 'Negative', 'Negative',\n",
       "       'Negative', 'Negative', 'Positive', 'Negative', 'Negative',\n",
       "       'Positive', 'Negative', 'Positive', 'Negative', 'Negative',\n",
       "       'Positive', 'Positive', 'Negative', 'Positive', 'Negative',\n",
       "       'Negative', 'Positive', 'Negative', 'Negative', 'Negative',\n",
       "       'Negative', 'Positive', 'Negative', 'Negative', 'Negative',\n",
       "       'Positive', 'Negative', 'Negative', 'Negative', 'Positive',\n",
       "       'Positive', 'Negative', 'Negative', 'Negative', 'Negative',\n",
       "       'Negative', 'Negative', 'Positive', 'Positive', 'Negative',\n",
       "       'Negative', 'Negative', 'Negative', 'Positive', 'Positive',\n",
       "       'Negative', 'Positive', 'Positive', 'Negative', 'Positive',\n",
       "       'Positive', 'Negative', 'Positive', 'Positive', 'Positive',\n",
       "       'Negative', 'Positive', 'Negative', 'Negative', 'Negative',\n",
       "       'Negative', 'Positive', 'Negative', 'Positive', 'Positive',\n",
       "       'Negative', 'Negative', 'Negative', 'Positive', 'Positive',\n",
       "       'Positive', 'Negative', 'Positive', 'Positive', 'Negative',\n",
       "       'Negative', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Negative', 'Negative', 'Negative', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Negative', 'Negative', 'Negative',\n",
       "       'Positive', 'Negative', 'Negative', 'Positive', 'Positive',\n",
       "       'Negative', 'Positive', 'Negative', 'Positive', 'Positive',\n",
       "       'Positive', 'Negative', 'Positive', 'Positive', 'Negative',\n",
       "       'Positive', 'Positive', 'Negative', 'Negative', 'Negative',\n",
       "       'Positive', 'Negative', 'Negative', 'Negative', 'Positive',\n",
       "       'Positive', 'Negative', 'Negative', 'Negative', 'Negative',\n",
       "       'Positive', 'Positive', 'Positive', 'Negative', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Negative',\n",
       "       'Positive', 'Negative', 'Positive', 'Positive', 'Positive',\n",
       "       'Negative', 'Positive', 'Positive', 'Positive', 'Negative',\n",
       "       'Negative', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Negative', 'Negative', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Negative', 'Positive', 'Positive', 'Positive',\n",
       "       'Negative', 'Negative', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Negative', 'Negative',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Negative', 'Positive', 'Positive', 'Negative', 'Positive',\n",
       "       'Negative', 'Positive', 'Negative', 'Positive', 'Positive',\n",
       "       'Negative', 'Positive', 'Negative', 'Positive', 'Negative',\n",
       "       'Negative', 'Negative', 'Negative', 'Positive', 'Negative',\n",
       "       'Positive', 'Positive', 'Negative', 'Positive', 'Negative',\n",
       "       'Negative', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Negative', 'Negative', 'Negative', 'Negative',\n",
       "       'Negative', 'Negative', 'Negative', 'Negative', 'Positive',\n",
       "       'Negative', 'Negative', 'Negative', 'Negative', 'Positive',\n",
       "       'Positive', 'Positive', 'Negative', 'Positive', 'Positive',\n",
       "       'Negative', 'Positive', 'Negative', 'Negative', 'Positive',\n",
       "       'Negative', 'Negative', 'Positive', 'Positive', 'Positive',\n",
       "       'Negative', 'Negative', 'Positive', 'Negative', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Negative',\n",
       "       'Positive', 'Negative', 'Positive', 'Negative', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive'], dtype='<U8')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Deployment***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>object_id</th>\n",
       "      <th>message</th>\n",
       "      <th>created_time</th>\n",
       "      <th>like_count</th>\n",
       "      <th>comment_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>253</td>\n",
       "      <td>4</td>\n",
       "      <td>5385637364812223_5389760717733221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-04-02 09:10:48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>254</td>\n",
       "      <td>4</td>\n",
       "      <td>5385637364812223_5391297577579535</td>\n",
       "      <td>:D</td>\n",
       "      <td>2021-04-02 16:09:18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>255</td>\n",
       "      <td>4</td>\n",
       "      <td>5385637364812223_5391709464205013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-04-02 18:27:53</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>5385637364812223_5400254766683816</td>\n",
       "      <td>🥰</td>\n",
       "      <td>2021-04-04 09:14:45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>267</td>\n",
       "      <td>9</td>\n",
       "      <td>5260239854018642_5322553797787247</td>\n",
       "      <td>Daniela Gilces</td>\n",
       "      <td>2021-03-18 20:15:21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  parent_id                          object_id          message  \\\n",
       "0  253          4  5385637364812223_5389760717733221              NaN   \n",
       "1  254          4  5385637364812223_5391297577579535              :D    \n",
       "2  255          4  5385637364812223_5391709464205013              NaN   \n",
       "3  256          4  5385637364812223_5400254766683816                🥰   \n",
       "4  267          9  5260239854018642_5322553797787247  Daniela Gilces    \n",
       "\n",
       "         created_time  like_count  comment_count  \n",
       "0 2021-04-02 09:10:48         0.0            1.0  \n",
       "1 2021-04-02 16:09:18         0.0            0.0  \n",
       "2 2021-04-02 18:27:53         1.0            1.0  \n",
       "3 2021-04-04 09:14:45         0.0            0.0  \n",
       "4 2021-03-18 20:15:21         0.0            0.0  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delilu= pd.read_excel(r'C:\\Users\\joel-\\Documents\\Tesis\\commentsdelilu.xlsx')\n",
    "delilu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>object_id</th>\n",
       "      <th>message</th>\n",
       "      <th>created_time</th>\n",
       "      <th>like_count</th>\n",
       "      <th>comment_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>254</td>\n",
       "      <td>4</td>\n",
       "      <td>5385637364812223_5391297577579535</td>\n",
       "      <td>:D</td>\n",
       "      <td>2021-04-02 16:09:18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>5385637364812223_5400254766683816</td>\n",
       "      <td>🥰</td>\n",
       "      <td>2021-04-04 09:14:45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>267</td>\n",
       "      <td>9</td>\n",
       "      <td>5260239854018642_5322553797787247</td>\n",
       "      <td>Daniela Gilces</td>\n",
       "      <td>2021-03-18 20:15:21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>270</td>\n",
       "      <td>10</td>\n",
       "      <td>5260235984019029_5265073256868635</td>\n",
       "      <td>La que me gusta con delilu😈🥵😳</td>\n",
       "      <td>2021-03-05 22:58:38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>271</td>\n",
       "      <td>10</td>\n",
       "      <td>5260235984019029_5275797155796245</td>\n",
       "      <td>Leí me vine en Lulú ._.</td>\n",
       "      <td>2021-03-08 11:55:28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  parent_id                          object_id  \\\n",
       "1  254          4  5385637364812223_5391297577579535   \n",
       "3  256          4  5385637364812223_5400254766683816   \n",
       "4  267          9  5260239854018642_5322553797787247   \n",
       "5  270         10  5260235984019029_5265073256868635   \n",
       "6  271         10  5260235984019029_5275797155796245   \n",
       "\n",
       "                         message        created_time  like_count  \\\n",
       "1                            :D  2021-04-02 16:09:18         0.0   \n",
       "3                              🥰 2021-04-04 09:14:45         0.0   \n",
       "4                Daniela Gilces  2021-03-18 20:15:21         0.0   \n",
       "5  La que me gusta con delilu😈🥵😳 2021-03-05 22:58:38         0.0   \n",
       "6        Leí me vine en Lulú ._. 2021-03-08 11:55:28         0.0   \n",
       "\n",
       "   comment_count  \n",
       "1            0.0  \n",
       "3            0.0  \n",
       "4            0.0  \n",
       "5            1.0  \n",
       "6            1.0  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delilu.dropna(inplace=True)\n",
    "delilu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "delilu['message'] = delilu['message'].apply(lambda x: re.split('https:\\/\\/.*', str(x))[0]) #elimina url\n",
    "delilu['message'] = delilu['message'].apply(lambda x: re.split('\\d+', str(x))[0]) #elimina palabras con numeros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>object_id</th>\n",
       "      <th>message</th>\n",
       "      <th>created_time</th>\n",
       "      <th>like_count</th>\n",
       "      <th>comment_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>254</td>\n",
       "      <td>4</td>\n",
       "      <td>5385637364812223_5391297577579535</td>\n",
       "      <td>:D</td>\n",
       "      <td>2021-04-02 16:09:18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>5385637364812223_5400254766683816</td>\n",
       "      <td>🥰</td>\n",
       "      <td>2021-04-04 09:14:45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>267</td>\n",
       "      <td>9</td>\n",
       "      <td>5260239854018642_5322553797787247</td>\n",
       "      <td>Daniela Gilces</td>\n",
       "      <td>2021-03-18 20:15:21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>270</td>\n",
       "      <td>10</td>\n",
       "      <td>5260235984019029_5265073256868635</td>\n",
       "      <td>La que me gusta con delilu😈🥵😳</td>\n",
       "      <td>2021-03-05 22:58:38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>271</td>\n",
       "      <td>10</td>\n",
       "      <td>5260235984019029_5275797155796245</td>\n",
       "      <td>Leí me vine en Lulú ._.</td>\n",
       "      <td>2021-03-08 11:55:28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3896</th>\n",
       "      <td>4823</td>\n",
       "      <td>234</td>\n",
       "      <td>2130376903671635_2135123219863670</td>\n",
       "      <td>son ricas ya me compre un par</td>\n",
       "      <td>2018-06-30 23:33:16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3897</th>\n",
       "      <td>4834</td>\n",
       "      <td>239</td>\n",
       "      <td>2081255925250400_2108765545832771</td>\n",
       "      <td>note estoy en las nubes</td>\n",
       "      <td>2018-06-16 23:14:51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3898</th>\n",
       "      <td>4835</td>\n",
       "      <td>239</td>\n",
       "      <td>2081255925250400_2116303475078978</td>\n",
       "      <td>Wow👌</td>\n",
       "      <td>2018-06-20 23:58:45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3899</th>\n",
       "      <td>4840</td>\n",
       "      <td>241</td>\n",
       "      <td>2111276798914979_2121492991226693</td>\n",
       "      <td>que asco de momo</td>\n",
       "      <td>2018-06-23 15:14:10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3900</th>\n",
       "      <td>4841</td>\n",
       "      <td>241</td>\n",
       "      <td>2111276798914979_2121751374534188</td>\n",
       "      <td>Jajajajajaja Jen Dashita Alava Mendoza 😂😂</td>\n",
       "      <td>2018-06-23 18:48:42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3165 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  parent_id                          object_id  \\\n",
       "1      254          4  5385637364812223_5391297577579535   \n",
       "3      256          4  5385637364812223_5400254766683816   \n",
       "4      267          9  5260239854018642_5322553797787247   \n",
       "5      270         10  5260235984019029_5265073256868635   \n",
       "6      271         10  5260235984019029_5275797155796245   \n",
       "...    ...        ...                                ...   \n",
       "3896  4823        234  2130376903671635_2135123219863670   \n",
       "3897  4834        239  2081255925250400_2108765545832771   \n",
       "3898  4835        239  2081255925250400_2116303475078978   \n",
       "3899  4840        241  2111276798914979_2121492991226693   \n",
       "3900  4841        241  2111276798914979_2121751374534188   \n",
       "\n",
       "                                        message        created_time  \\\n",
       "1                                           :D  2021-04-02 16:09:18   \n",
       "3                                             🥰 2021-04-04 09:14:45   \n",
       "4                               Daniela Gilces  2021-03-18 20:15:21   \n",
       "5                 La que me gusta con delilu😈🥵😳 2021-03-05 22:58:38   \n",
       "6                       Leí me vine en Lulú ._. 2021-03-08 11:55:28   \n",
       "...                                         ...                 ...   \n",
       "3896              son ricas ya me compre un par 2018-06-30 23:33:16   \n",
       "3897                    note estoy en las nubes 2018-06-16 23:14:51   \n",
       "3898                                       Wow👌 2018-06-20 23:58:45   \n",
       "3899                           que asco de momo 2018-06-23 15:14:10   \n",
       "3900  Jajajajajaja Jen Dashita Alava Mendoza 😂😂 2018-06-23 18:48:42   \n",
       "\n",
       "      like_count  comment_count  \n",
       "1            0.0            0.0  \n",
       "3            0.0            0.0  \n",
       "4            0.0            0.0  \n",
       "5            0.0            1.0  \n",
       "6            0.0            1.0  \n",
       "...          ...            ...  \n",
       "3896         0.0            0.0  \n",
       "3897         1.0            0.0  \n",
       "3898         0.0            0.0  \n",
       "3899         0.0            0.0  \n",
       "3900         0.0            0.0  \n",
       "\n",
       "[3165 rows x 7 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#elimina palabras con letras repetidas\n",
    "def conti_rep_char(str1):\n",
    "    tchr = str1.group(0)\n",
    "    if len(tchr) > 1:\n",
    "      return tchr[0:1]\n",
    "      \n",
    "def check_unique_char(rep, sent_text):\n",
    "    \n",
    "    convert = re.sub(r'(\\w)\\1+', rep,sent_text)\n",
    "      \n",
    "    #regresa la palabra convertida\n",
    "    return convert\n",
    "  \n",
    "delilu['message'] = delilu['message'].apply(lambda x : check_unique_char(conti_rep_char,x))\n",
    "delilu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>carasonriendoconcorazones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>daniela gilces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gusta delilu carasonriendoconcuernos caraconca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lei vine lulu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3896</th>\n",
       "      <td>ricas compre par</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3897</th>\n",
       "      <td>note nubes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3898</th>\n",
       "      <td>wow señaldeaprobacionconlamano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3899</th>\n",
       "      <td>asco momo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3900</th>\n",
       "      <td>jajajajajaja jen dashita alava mendoza carallo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3165 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                message\n",
       "1                                                      \n",
       "3                             carasonriendoconcorazones\n",
       "4                                        daniela gilces\n",
       "5     gusta delilu carasonriendoconcuernos caraconca...\n",
       "6                                         lei vine lulu\n",
       "...                                                 ...\n",
       "3896                                   ricas compre par\n",
       "3897                                         note nubes\n",
       "3898                     wow señaldeaprobacionconlamano\n",
       "3899                                          asco momo\n",
       "3900  jajajajajaja jen dashita alava mendoza carallo...\n",
       "\n",
       "[3165 rows x 1 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delilu['message']\n",
    "delilu['message'] = delilu['message'].apply(get_mentions_processing)\n",
    "delilu['message']= delilu['message'].apply(get_hashtags_processing)\n",
    "delilu['message'] = delilu['message'].apply(get_emojis_processing)\n",
    "delilu['message'] = delilu['message'].apply(get_text_processing)\n",
    "delilu['message']= delilu['message'].apply(get_less3words_processing)\n",
    "delilu['message'] = delilu['message'].apply(normalize)\n",
    "delilu[['message']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(2571, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>object_id</th>\n",
       "      <th>message</th>\n",
       "      <th>created_time</th>\n",
       "      <th>like_count</th>\n",
       "      <th>comment_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>5385637364812223_5400254766683816</td>\n",
       "      <td>carasonriendoconcorazones</td>\n",
       "      <td>2021-04-04 09:14:45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>267</td>\n",
       "      <td>9</td>\n",
       "      <td>5260239854018642_5322553797787247</td>\n",
       "      <td>daniela gilces</td>\n",
       "      <td>2021-03-18 20:15:21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>270</td>\n",
       "      <td>10</td>\n",
       "      <td>5260235984019029_5265073256868635</td>\n",
       "      <td>gusta delilu carasonriendoconcuernos caraconca...</td>\n",
       "      <td>2021-03-05 22:58:38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>271</td>\n",
       "      <td>10</td>\n",
       "      <td>5260235984019029_5275797155796245</td>\n",
       "      <td>lei vine lulu</td>\n",
       "      <td>2021-03-08 11:55:28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>272</td>\n",
       "      <td>10</td>\n",
       "      <td>5260235984019029_5275846755791285</td>\n",
       "      <td>nunca falte delilu</td>\n",
       "      <td>2021-03-08 12:09:19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3896</th>\n",
       "      <td>4823</td>\n",
       "      <td>234</td>\n",
       "      <td>2130376903671635_2135123219863670</td>\n",
       "      <td>ricas compre par</td>\n",
       "      <td>2018-06-30 23:33:16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3897</th>\n",
       "      <td>4834</td>\n",
       "      <td>239</td>\n",
       "      <td>2081255925250400_2108765545832771</td>\n",
       "      <td>note nubes</td>\n",
       "      <td>2018-06-16 23:14:51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3898</th>\n",
       "      <td>4835</td>\n",
       "      <td>239</td>\n",
       "      <td>2081255925250400_2116303475078978</td>\n",
       "      <td>wow señaldeaprobacionconlamano</td>\n",
       "      <td>2018-06-20 23:58:45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3899</th>\n",
       "      <td>4840</td>\n",
       "      <td>241</td>\n",
       "      <td>2111276798914979_2121492991226693</td>\n",
       "      <td>asco momo</td>\n",
       "      <td>2018-06-23 15:14:10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3900</th>\n",
       "      <td>4841</td>\n",
       "      <td>241</td>\n",
       "      <td>2111276798914979_2121751374534188</td>\n",
       "      <td>jajajajajaja jen dashita alava mendoza carallo...</td>\n",
       "      <td>2018-06-23 18:48:42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2571 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  parent_id                          object_id  \\\n",
       "3      256          4  5385637364812223_5400254766683816   \n",
       "4      267          9  5260239854018642_5322553797787247   \n",
       "5      270         10  5260235984019029_5265073256868635   \n",
       "6      271         10  5260235984019029_5275797155796245   \n",
       "7      272         10  5260235984019029_5275846755791285   \n",
       "...    ...        ...                                ...   \n",
       "3896  4823        234  2130376903671635_2135123219863670   \n",
       "3897  4834        239  2081255925250400_2108765545832771   \n",
       "3898  4835        239  2081255925250400_2116303475078978   \n",
       "3899  4840        241  2111276798914979_2121492991226693   \n",
       "3900  4841        241  2111276798914979_2121751374534188   \n",
       "\n",
       "                                                message        created_time  \\\n",
       "3                             carasonriendoconcorazones 2021-04-04 09:14:45   \n",
       "4                                        daniela gilces 2021-03-18 20:15:21   \n",
       "5     gusta delilu carasonriendoconcuernos caraconca... 2021-03-05 22:58:38   \n",
       "6                                         lei vine lulu 2021-03-08 11:55:28   \n",
       "7                                    nunca falte delilu 2021-03-08 12:09:19   \n",
       "...                                                 ...                 ...   \n",
       "3896                                   ricas compre par 2018-06-30 23:33:16   \n",
       "3897                                         note nubes 2018-06-16 23:14:51   \n",
       "3898                     wow señaldeaprobacionconlamano 2018-06-20 23:58:45   \n",
       "3899                                          asco momo 2018-06-23 15:14:10   \n",
       "3900  jajajajajaja jen dashita alava mendoza carallo... 2018-06-23 18:48:42   \n",
       "\n",
       "      like_count  comment_count  \n",
       "3            0.0            0.0  \n",
       "4            0.0            0.0  \n",
       "5            0.0            1.0  \n",
       "6            0.0            1.0  \n",
       "7            0.0            0.0  \n",
       "...          ...            ...  \n",
       "3896         0.0            0.0  \n",
       "3897         1.0            0.0  \n",
       "3898         0.0            0.0  \n",
       "3899         0.0            0.0  \n",
       "3900         0.0            0.0  \n",
       "\n",
       "[2571 rows x 7 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delilu['message'].replace('', np.nan, inplace=True) # Reemplazo los registros vacíos con NaN\n",
    "print(delilu['message'].isna().sum()) \n",
    "delilu.dropna(axis=0, subset=['message'],inplace=True)\n",
    "print(delilu.shape)\n",
    "delilu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2571,)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textos=delilu['message'].values\n",
    "textos.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_deploy = vect1.transform(textos)\n",
    "X_deploy = tfidf.transform(X_deploy)\n",
    "X_deploy = X_deploy.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "preddelilu = model.predict(X_deploy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0215026e-05, 9.9987113e-01, 1.1864152e-04],\n",
       "       [9.6325672e-01, 2.3513781e-02, 1.3229430e-02],\n",
       "       [5.7554539e-09, 1.6162552e-02, 9.8383743e-01],\n",
       "       ...,\n",
       "       [1.9071965e-06, 9.8384780e-01, 1.6150311e-02],\n",
       "       [9.8802060e-01, 1.1772936e-02, 2.0643907e-04],\n",
       "       [1.3265784e-05, 9.9943501e-01, 5.5170699e-04]], dtype=float32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preddelilu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neutral', 'Negative', 'Positive', ..., 'Neutral', 'Negative',\n",
       "       'Neutral'], dtype='<U8')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentimientos=encoder.inverse_transform(preddelilu)\n",
    "sentimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567</th>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2568</th>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2570</th>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2571 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label\n",
       "0      Neutral\n",
       "1     Negative\n",
       "2     Positive\n",
       "3     Negative\n",
       "4     Positive\n",
       "...        ...\n",
       "2566  Positive\n",
       "2567  Negative\n",
       "2568   Neutral\n",
       "2569  Negative\n",
       "2570   Neutral\n",
       "\n",
       "[2571 rows x 1 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label=pd.DataFrame(sentimientos, columns = ['label'])\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "delilu['sentiment']=label['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AxesSubplot' object has no property 'fontsize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-183-6fbabbd1eebd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Sentiment\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of Comments\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcountplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sentiment'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdelilu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'summer'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfavorita\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentiment'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Number of Comments by Sentiment\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   1111\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmove_color_to_start\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"color\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"color\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1113\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfindobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_self\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, props)\u001b[0m\n\u001b[0;32m    994\u001b[0m                     \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"set_{k}\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    995\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 996\u001b[1;33m                         raise AttributeError(f\"{type(self).__name__!r} object \"\n\u001b[0m\u001b[0;32m    997\u001b[0m                                              f\"has no property {k!r}\")\n\u001b[0;32m    998\u001b[0m                     \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'AxesSubplot' object has no property 'fontsize'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('whitegrid')\n",
    "plt.xticks(size=13)\n",
    "plt.yticks(size=13)\n",
    "plt.xlabel(\"Sentiment\",fontsize=15)\n",
    "plt.ylabel(\"Number of Comments\", fontsize=15)\n",
    "a=sns.countplot(x='sentiment',data=delilu, palette='summer',order = favorita['sentiment'].value_counts().index).set(title=\"Number of Comments by Sentiment\",fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La favorita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>object_id</th>\n",
       "      <th>message</th>\n",
       "      <th>created_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2411</td>\n",
       "      <td>48</td>\n",
       "      <td>3513707055341384_3550269558351800</td>\n",
       "      <td>#CocinandoConLaFavorita mi rico encebollado d...</td>\n",
       "      <td>2020-08-12 22:03:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2412</td>\n",
       "      <td>48</td>\n",
       "      <td>3513707055341384_3550280388350717</td>\n",
       "      <td>#CocinandoConLaFavorita mis ricas empanadas d...</td>\n",
       "      <td>2020-08-12 22:08:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2378</td>\n",
       "      <td>48</td>\n",
       "      <td>3513707055341384_3531473420231414</td>\n",
       "      <td>#CocinandoConLaFavorita Participando con un e...</td>\n",
       "      <td>2020-08-06 12:50:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2380</td>\n",
       "      <td>48</td>\n",
       "      <td>3513707055341384_3531709220207834</td>\n",
       "      <td>#Cocinandoconlafavorita un delicioso moro mix...</td>\n",
       "      <td>2020-08-06 14:27:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2537</td>\n",
       "      <td>60</td>\n",
       "      <td>3376308765747881_3381054451939979</td>\n",
       "      <td>#DiaDelPadre #PapaDeLasHamburguesas #Favorita...</td>\n",
       "      <td>2020-06-14 09:50:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  parent_id                          object_id  \\\n",
       "0  2411         48  3513707055341384_3550269558351800   \n",
       "1  2412         48  3513707055341384_3550280388350717   \n",
       "2  2378         48  3513707055341384_3531473420231414   \n",
       "3  2380         48  3513707055341384_3531709220207834   \n",
       "4  2537         60  3376308765747881_3381054451939979   \n",
       "\n",
       "                                             message        created_time  \n",
       "0   #CocinandoConLaFavorita mi rico encebollado d... 2020-08-12 22:03:55  \n",
       "1   #CocinandoConLaFavorita mis ricas empanadas d... 2020-08-12 22:08:54  \n",
       "2   #CocinandoConLaFavorita Participando con un e... 2020-08-06 12:50:22  \n",
       "3   #Cocinandoconlafavorita un delicioso moro mix... 2020-08-06 14:27:35  \n",
       "4   #DiaDelPadre #PapaDeLasHamburguesas #Favorita... 2020-06-14 09:50:16  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "favorita= pd.read_excel(r'C:\\Users\\joel-\\Documents\\Tesis\\commentsfavorita.xlsx')\n",
    "favorita.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>object_id</th>\n",
       "      <th>message</th>\n",
       "      <th>created_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2411</td>\n",
       "      <td>48</td>\n",
       "      <td>3513707055341384_3550269558351800</td>\n",
       "      <td>#CocinandoConLaFavorita mi rico encebollado d...</td>\n",
       "      <td>2020-08-12 22:03:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2412</td>\n",
       "      <td>48</td>\n",
       "      <td>3513707055341384_3550280388350717</td>\n",
       "      <td>#CocinandoConLaFavorita mis ricas empanadas d...</td>\n",
       "      <td>2020-08-12 22:08:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2378</td>\n",
       "      <td>48</td>\n",
       "      <td>3513707055341384_3531473420231414</td>\n",
       "      <td>#CocinandoConLaFavorita Participando con un e...</td>\n",
       "      <td>2020-08-06 12:50:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2380</td>\n",
       "      <td>48</td>\n",
       "      <td>3513707055341384_3531709220207834</td>\n",
       "      <td>#Cocinandoconlafavorita un delicioso moro mix...</td>\n",
       "      <td>2020-08-06 14:27:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2537</td>\n",
       "      <td>60</td>\n",
       "      <td>3376308765747881_3381054451939979</td>\n",
       "      <td>#DiaDelPadre #PapaDeLasHamburguesas #Favorita...</td>\n",
       "      <td>2020-06-14 09:50:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  parent_id                          object_id  \\\n",
       "0  2411         48  3513707055341384_3550269558351800   \n",
       "1  2412         48  3513707055341384_3550280388350717   \n",
       "2  2378         48  3513707055341384_3531473420231414   \n",
       "3  2380         48  3513707055341384_3531709220207834   \n",
       "4  2537         60  3376308765747881_3381054451939979   \n",
       "\n",
       "                                             message        created_time  \n",
       "0   #CocinandoConLaFavorita mi rico encebollado d... 2020-08-12 22:03:55  \n",
       "1   #CocinandoConLaFavorita mis ricas empanadas d... 2020-08-12 22:08:54  \n",
       "2   #CocinandoConLaFavorita Participando con un e... 2020-08-06 12:50:22  \n",
       "3   #Cocinandoconlafavorita un delicioso moro mix... 2020-08-06 14:27:35  \n",
       "4   #DiaDelPadre #PapaDeLasHamburguesas #Favorita... 2020-06-14 09:50:16  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "favorita.dropna(inplace=True)\n",
    "favorita.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "favorita['message'] = favorita['message'].apply(lambda x: re.split('https:\\/\\/.*', str(x))[0]) #elimina url\n",
    "favorita['message'] = favorita['message'].apply(lambda x: re.split('\\d+', str(x))[0]) #elimina palabras con numeros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>object_id</th>\n",
       "      <th>message</th>\n",
       "      <th>created_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2411</td>\n",
       "      <td>48</td>\n",
       "      <td>3513707055341384_3550269558351800</td>\n",
       "      <td>#CocinandoConLaFavorita mi rico encebolado de...</td>\n",
       "      <td>2020-08-12 22:03:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2412</td>\n",
       "      <td>48</td>\n",
       "      <td>3513707055341384_3550280388350717</td>\n",
       "      <td>#CocinandoConLaFavorita mis ricas empanadas d...</td>\n",
       "      <td>2020-08-12 22:08:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2378</td>\n",
       "      <td>48</td>\n",
       "      <td>3513707055341384_3531473420231414</td>\n",
       "      <td>#CocinandoConLaFavorita Participando con un e...</td>\n",
       "      <td>2020-08-06 12:50:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2380</td>\n",
       "      <td>48</td>\n",
       "      <td>3513707055341384_3531709220207834</td>\n",
       "      <td>#Cocinandoconlafavorita un delicioso moro mix...</td>\n",
       "      <td>2020-08-06 14:27:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2537</td>\n",
       "      <td>60</td>\n",
       "      <td>3376308765747881_3381054451939979</td>\n",
       "      <td>#DiaDelPadre #PapaDeLasHamburguesas #Favorita...</td>\n",
       "      <td>2020-06-14 09:50:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8975</th>\n",
       "      <td>1689</td>\n",
       "      <td>11</td>\n",
       "      <td>4007174879327930_4026103700768381</td>\n",
       "      <td>🥰</td>\n",
       "      <td>2021-01-25 10:05:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8976</th>\n",
       "      <td>1912</td>\n",
       "      <td>23</td>\n",
       "      <td>3905710489474370_3950134178365334</td>\n",
       "      <td>🥰</td>\n",
       "      <td>2020-12-27 19:15:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8977</th>\n",
       "      <td>3733</td>\n",
       "      <td>92</td>\n",
       "      <td>3176765452368881_3196035400441886</td>\n",
       "      <td>🥰</td>\n",
       "      <td>2020-04-02 09:51:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8978</th>\n",
       "      <td>2119</td>\n",
       "      <td>29</td>\n",
       "      <td>3842378939140859_3842925522419534</td>\n",
       "      <td>🥳</td>\n",
       "      <td>2020-11-17 17:08:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8979</th>\n",
       "      <td>3794</td>\n",
       "      <td>98</td>\n",
       "      <td>3115014021877358_3121345874577506</td>\n",
       "      <td>🥳</td>\n",
       "      <td>2020-03-01 09:34:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8980 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  parent_id                          object_id  \\\n",
       "0     2411         48  3513707055341384_3550269558351800   \n",
       "1     2412         48  3513707055341384_3550280388350717   \n",
       "2     2378         48  3513707055341384_3531473420231414   \n",
       "3     2380         48  3513707055341384_3531709220207834   \n",
       "4     2537         60  3376308765747881_3381054451939979   \n",
       "...    ...        ...                                ...   \n",
       "8975  1689         11  4007174879327930_4026103700768381   \n",
       "8976  1912         23  3905710489474370_3950134178365334   \n",
       "8977  3733         92  3176765452368881_3196035400441886   \n",
       "8978  2119         29  3842378939140859_3842925522419534   \n",
       "8979  3794         98  3115014021877358_3121345874577506   \n",
       "\n",
       "                                                message        created_time  \n",
       "0      #CocinandoConLaFavorita mi rico encebolado de... 2020-08-12 22:03:55  \n",
       "1      #CocinandoConLaFavorita mis ricas empanadas d... 2020-08-12 22:08:54  \n",
       "2      #CocinandoConLaFavorita Participando con un e... 2020-08-06 12:50:22  \n",
       "3      #Cocinandoconlafavorita un delicioso moro mix... 2020-08-06 14:27:35  \n",
       "4      #DiaDelPadre #PapaDeLasHamburguesas #Favorita... 2020-06-14 09:50:16  \n",
       "...                                                 ...                 ...  \n",
       "8975                                                  🥰 2021-01-25 10:05:50  \n",
       "8976                                                  🥰 2020-12-27 19:15:27  \n",
       "8977                                                  🥰 2020-04-02 09:51:01  \n",
       "8978                                                  🥳 2020-11-17 17:08:28  \n",
       "8979                                                  🥳 2020-03-01 09:34:53  \n",
       "\n",
       "[8980 rows x 5 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#elimina palabras con letras repetidas\n",
    "def conti_rep_char(str1):\n",
    "    tchr = str1.group(0)\n",
    "    if len(tchr) > 1:\n",
    "      return tchr[0:1]\n",
    "      \n",
    "def check_unique_char(rep, sent_text):\n",
    "    \n",
    "    convert = re.sub(r'(\\w)\\1+', rep,sent_text)\n",
    "      \n",
    "    #regresa la palabra convertida\n",
    "    return convert\n",
    "  \n",
    "favorita['message'] = favorita['message'].apply(lambda x : check_unique_char(conti_rep_char,x))\n",
    "favorita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rico encebolado albacora preparado aceite favo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ricas empanadas polo carne venta emprendimient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>participando exquisito yapingacho preparado am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>delicioso moro mixto polo chancho chuzo cuenca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hamburguesa hamburguesa hamburguesa kleber ale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8975</th>\n",
       "      <td>carasonriendoconcorazones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8976</th>\n",
       "      <td>carasonriendoconcorazones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8977</th>\n",
       "      <td>carasonriendoconcorazones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8978</th>\n",
       "      <td>caradefiesta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8979</th>\n",
       "      <td>caradefiesta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8980 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                message\n",
       "0     rico encebolado albacora preparado aceite favo...\n",
       "1     ricas empanadas polo carne venta emprendimient...\n",
       "2     participando exquisito yapingacho preparado am...\n",
       "3     delicioso moro mixto polo chancho chuzo cuenca...\n",
       "4     hamburguesa hamburguesa hamburguesa kleber ale...\n",
       "...                                                 ...\n",
       "8975                          carasonriendoconcorazones\n",
       "8976                          carasonriendoconcorazones\n",
       "8977                          carasonriendoconcorazones\n",
       "8978                                       caradefiesta\n",
       "8979                                       caradefiesta\n",
       "\n",
       "[8980 rows x 1 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "favorita['message']\n",
    "favorita['message'] = favorita['message'].apply(get_mentions_processing)\n",
    "favorita['message']= favorita['message'].apply(get_hashtags_processing)\n",
    "favorita['message'] = favorita['message'].apply(get_emojis_processing)\n",
    "favorita['message'] = favorita['message'].apply(get_text_processing)\n",
    "favorita['message']= favorita['message'].apply(get_less3words_processing)\n",
    "favorita['message'] = favorita['message'].apply(normalize)\n",
    "favorita[['message']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309\n",
      "(8671, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>object_id</th>\n",
       "      <th>message</th>\n",
       "      <th>created_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2411</td>\n",
       "      <td>48</td>\n",
       "      <td>3513707055341384_3550269558351800</td>\n",
       "      <td>rico encebolado albacora preparado aceite favo...</td>\n",
       "      <td>2020-08-12 22:03:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2412</td>\n",
       "      <td>48</td>\n",
       "      <td>3513707055341384_3550280388350717</td>\n",
       "      <td>ricas empanadas polo carne venta emprendimient...</td>\n",
       "      <td>2020-08-12 22:08:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2378</td>\n",
       "      <td>48</td>\n",
       "      <td>3513707055341384_3531473420231414</td>\n",
       "      <td>participando exquisito yapingacho preparado am...</td>\n",
       "      <td>2020-08-06 12:50:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2380</td>\n",
       "      <td>48</td>\n",
       "      <td>3513707055341384_3531709220207834</td>\n",
       "      <td>delicioso moro mixto polo chancho chuzo cuenca...</td>\n",
       "      <td>2020-08-06 14:27:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2537</td>\n",
       "      <td>60</td>\n",
       "      <td>3376308765747881_3381054451939979</td>\n",
       "      <td>hamburguesa hamburguesa hamburguesa kleber ale...</td>\n",
       "      <td>2020-06-14 09:50:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8975</th>\n",
       "      <td>1689</td>\n",
       "      <td>11</td>\n",
       "      <td>4007174879327930_4026103700768381</td>\n",
       "      <td>carasonriendoconcorazones</td>\n",
       "      <td>2021-01-25 10:05:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8976</th>\n",
       "      <td>1912</td>\n",
       "      <td>23</td>\n",
       "      <td>3905710489474370_3950134178365334</td>\n",
       "      <td>carasonriendoconcorazones</td>\n",
       "      <td>2020-12-27 19:15:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8977</th>\n",
       "      <td>3733</td>\n",
       "      <td>92</td>\n",
       "      <td>3176765452368881_3196035400441886</td>\n",
       "      <td>carasonriendoconcorazones</td>\n",
       "      <td>2020-04-02 09:51:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8978</th>\n",
       "      <td>2119</td>\n",
       "      <td>29</td>\n",
       "      <td>3842378939140859_3842925522419534</td>\n",
       "      <td>caradefiesta</td>\n",
       "      <td>2020-11-17 17:08:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8979</th>\n",
       "      <td>3794</td>\n",
       "      <td>98</td>\n",
       "      <td>3115014021877358_3121345874577506</td>\n",
       "      <td>caradefiesta</td>\n",
       "      <td>2020-03-01 09:34:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8671 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  parent_id                          object_id  \\\n",
       "0     2411         48  3513707055341384_3550269558351800   \n",
       "1     2412         48  3513707055341384_3550280388350717   \n",
       "2     2378         48  3513707055341384_3531473420231414   \n",
       "3     2380         48  3513707055341384_3531709220207834   \n",
       "4     2537         60  3376308765747881_3381054451939979   \n",
       "...    ...        ...                                ...   \n",
       "8975  1689         11  4007174879327930_4026103700768381   \n",
       "8976  1912         23  3905710489474370_3950134178365334   \n",
       "8977  3733         92  3176765452368881_3196035400441886   \n",
       "8978  2119         29  3842378939140859_3842925522419534   \n",
       "8979  3794         98  3115014021877358_3121345874577506   \n",
       "\n",
       "                                                message        created_time  \n",
       "0     rico encebolado albacora preparado aceite favo... 2020-08-12 22:03:55  \n",
       "1     ricas empanadas polo carne venta emprendimient... 2020-08-12 22:08:54  \n",
       "2     participando exquisito yapingacho preparado am... 2020-08-06 12:50:22  \n",
       "3     delicioso moro mixto polo chancho chuzo cuenca... 2020-08-06 14:27:35  \n",
       "4     hamburguesa hamburguesa hamburguesa kleber ale... 2020-06-14 09:50:16  \n",
       "...                                                 ...                 ...  \n",
       "8975                          carasonriendoconcorazones 2021-01-25 10:05:50  \n",
       "8976                          carasonriendoconcorazones 2020-12-27 19:15:27  \n",
       "8977                          carasonriendoconcorazones 2020-04-02 09:51:01  \n",
       "8978                                       caradefiesta 2020-11-17 17:08:28  \n",
       "8979                                       caradefiesta 2020-03-01 09:34:53  \n",
       "\n",
       "[8671 rows x 5 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "favorita['message'].replace('', np.nan, inplace=True) # Reemplazo los registros vacíos con NaN\n",
    "print(favorita['message'].isna().sum()) \n",
    "favorita.dropna(axis=0, subset=['message'],inplace=True)\n",
    "print(favorita.shape)\n",
    "favorita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8671,)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textos=favorita['message'].values\n",
    "textos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_deploy = vect1.transform(textos)\n",
    "X_deploy = tfidf.transform(X_deploy)\n",
    "X_deploy = X_deploy.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "predfav = model.predict(X_deploy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Positive', 'Positive', 'Positive', ..., 'Neutral', 'Positive',\n",
       "       'Positive'], dtype='<U8')"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentimientos=encoder.inverse_transform(predfav)\n",
    "sentimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8666</th>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8667</th>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8668</th>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8669</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8671 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label\n",
       "0     Positive\n",
       "1     Positive\n",
       "2     Positive\n",
       "3     Positive\n",
       "4      Neutral\n",
       "...        ...\n",
       "8666   Neutral\n",
       "8667   Neutral\n",
       "8668   Neutral\n",
       "8669  Positive\n",
       "8670  Positive\n",
       "\n",
       "[8671 rows x 1 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label=pd.DataFrame(sentimientos, columns = ['label'])\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "favorita['sentiment']=label['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 1.0, 'Number of Comments by Sentiment')]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('whitegrid')\n",
    "plt.xticks(size=13)\n",
    "plt.yticks(size=13)\n",
    "plt.xlabel(\"Sentiment\",fontsize=15)\n",
    "plt.ylabel(\"Number of Comments\", fontsize=15)\n",
    "sns.countplot(x='sentiment',data=favorita, palette='summer',order = favorita['sentiment'].value_counts().index).set(title=\"Number of Comments by Sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
